{
  "0": {
    "title": "FDS-S1-08-1-high-dimensions",
    "content": [
      "Inf2 \u2013 Foundations of Data Science 2021 Topic: Dealing with high dimensions \u2013 PCA",
      "David C. Sterratt",
      "5th November 2021",
      "Intended learning objectives By the end of this topic you should be able to:",
      "1. Explain what sorts of datasets principal components analysis (PCA) can help us to under-  stand",
      "2. Explain the principle of how PCA works",
      "3. Outline the steps involved in the derivation of PCA",
      "4. Interpret the results of a PCA analysis",
      "Recommended reading: Neither of the course textbooks cover PCA. Witten, Frank, Hall and Pal Data mining, 4th 3d, pp 304\u2013307 contains an overview. Di\ufb00erent sources use di\ufb00erent notation, so it may be least confusing just to follow these notes.",
      "1 Video: The principle of Principal Components Analysis (PCA)",
      "The challenges of high dimensions In the multiple regression topic, in the student grade prediction example, we were beginning to see two challenges of dealing with more than one independent variable:",
      "The challenge of visualisation We can see a lot in the paired correlation plots. With 4 independent variables, the visualisation works, but what about if we had 26 variables? The Scottish Index of Multiple Deprivation (SIMD, Table 1) records 26 variables for each of 6527 data zones in Scotland. A 26\u00d726 grid of scatter plots is going to be di\ufb03cult to read.",
      "The challenge of interpretation In the grades example, the test grades (independent variables) were correlated, which made the interpretation of the regression coe\ufb03cients challenging \u2013 and this was with only 4 independent variables. In the SIMD example, we might expect many of the 26",
      "1  \fTable 1: Scottish Index of Multiple Deprivation, 2016 edition (Scottish Government, 2016). https: \/\/simd.scot. It has n = 6527 data points (postcode zones), each associated with D = 26 variables.",
      "Drive",
      "Crime  . . .",
      "Location Employ-  ment",
      "Macdu\ufb00 Kemnay Hilton Ruchill Belmont . . .",
      "10 3 0 8 2 . . .",
      "Illness Attain- Drive ment 5.3 5.3 6.3 4.9 6.1 . . .",
      "Primary Secondary 6.6 2.4 3.0 5.6 3.2 . . .",
      "95 40 10 130 50 . . .",
      "1.5 2.4 2.2 1.7 3.1 . . .",
      "249 168 144 318 129 . . .  . . . . . . . . . . . . . . . . . .  variables to be correlated, e.g. the time it takes to drive to the nearest primary school and the time it takes to drive to the nearest secondary school.",
      "There is also another problem with high-dimensional data, called the curse of dimensionality: essen- tially a large number of dimensions makes is harder for distance-based methods such as clustering and nearest neighbours to work e\ufb00ectively \u2013 we\u2019ll come back to the curse of dimensionality in the following lectures on clustering and nearest-neighbour methods.",
      "In dimensionality reduction methods these challenges are addressed by reducing the number of dimensions in the data while retaining as much useful information as possible. There are a number of dimensionality reduction methods which di\ufb00er in what aspects of the data they preserve.",
      "Principal components analysis We are going to discuss one method of dimensionality reduction called principal components analysis (PCA).",
      "PCA can be applied to a set of D numeric variables with n datapoints. In contrast to linear regression, all variables are treated equally: there is no dependent variable that we are trying to predict, just a set of variables whose structure we\u2019re trying to understand better. The result of PCA is a set of up to D new variables (with n datapoints). We can keep k \u2264 D of the most informative new variables.",
      "In PCA the objectives are:",
      "1. change the angle we view the data from to see things clearly",
      "2. ignore small details in the data that don\u2019t a\ufb00ect the big picture.",
      "We\u2019ll specify these objectives more precisely and explain how PCA works later. First, we will show the results when PCA is applied to the SIMD example (Table 1).",
      "Example of PCA We can use PCA to reduce the number of variables D in the SIMD data from D = 26 to k = 2, allowing us to visualise all n = 6527 data points (Figure 1). In this plot, the ith datapoint has coordinates (ti1, ti2) in which each coordinate is a linear combination of the standardised1 data zi j shown in Table 1:  ti1 = p11zi1 + p21zi2 + \u00b7 \u00b7 \u00b7 + pD1ziD ti2 = p12zi1 + p22zi2 + \u00b7 \u00b7 \u00b7 + pD2ziD  (1)",
      "1Remember from the video on variance that we standardise the jth variable x( j) by subtracting its mean x( j) and dividing by its standard deviation s j, so that zi j = (xi j \u2212 x( j))\/s j. Generally, the data we supply to PCA do not need to be standardised, we still do need to subtract the mean in order to compute the component scores. In the video lecture we use xs in the equivalent equation, and state that they are zero-mean versions of the variables.",
      "2  \fFigure 1: Scatter plot of \ufb01rst and second principal component scores (PC1 and PC2) of 6527 data points in the SIMD dataset (blue dots). Locations of 4 data zones are indicated in orange dots next to an image from that data zone. All photos released under CC licence from geograph.co.uk. Credits: Orkney \u00a9 Des Colhoun; Possil Park \u00a9 Stephen Sweeney; Brunst\ufb01eld \u00a9 Leslie Barrie; Fairmilehead \u00a9 Jim Barton.",
      "The weights p11, p21, . . . , pD1 are elements of the \ufb01rst principal component and ti1 is the \ufb01rst prin- cipal component score of the ith datapoint; we will explain how to \ufb01nd them later. Likewise, p12, p22, . . . , pD2 form the second principal component and ti1 is the second principal component score of datapoint i. The weights in the principal component indicate how much in\ufb02uence each original variable has over each principal component score \u2013 sometimes they are referred to as loadings or weights. The axes in Figure 1 are labelled PC1 and PC2 (PC stands for principal component).",
      "To see the in\ufb02uence of each original variable on PC1 and PC2 scores, we can project the jth original variable onto the plot by setting zi j to 1 and all the other z\u2019s to 0 in Equation 1. In this case, the coordinates we\u2019ll be plotting are (p j1, p j2). The orange arrows in Figure 2 show the projections of the variables for unemployment, overcrowding (in housing) and school attendance. Unemployment and overcrowding have high PC1 scores. In contrast, school attendance has a low PC1 score. This all makes sense if we identify the \ufb01rst component score with \u201cDeprivation\u201d. We can rephrase the previous sentences as \u201cunemployment and overcrowding are found in areas of high deprivation and high school attendance is found in areas of low deprivation\u201d.",
      "The red arrows in Figure 2 show the projections of the time to drive to the nearest retail outlet and time to drive to the nearest secondary school. These vectors have higher magnitude PC2 scores than PC1 scores. We therefore identify PC2 as being to do with \u201cremoteness\u201d \u2013 low values of PC2 indicate the zone is more remote.",
      "3",
      "1050510PC110.07.55.02.50.02.55.07.510.0PC2Glasgow Possil ParkOrkneyBruntsfieldFairmilehead\fFigure 2: Scatter plots of \ufb01rst and second principal component scores of SIMD data zones (blue dots). The projection of three original variables related to deprivation are shown as orange arrows emanating from the origin. High unemployment and overcrowded rate are found in areas with higher deprivation, whereas high school attendance is found in areas with low deprivation. These vectors are more closely aligned with the \ufb01rst principal component (PC1), which we therefore interpret as \u201cDeprivation\u201d. Red arrows indicate the projections of the time take to drive to the nearest secondary school or retail outlet. As these are aligned with PC2, we therefore interpret PC2 as being related to distance to services, or \u201cRemoteness\u201d.",
      "Note that the correlation between the PC1 and PC2 scores is zero. It is a general property of PCA there are no correlations between the scores of di\ufb00erent principal components. In this particular example, the visualisation shows a unimodal distribution of data with little obvious structure. Later on in the course we will see examples where PCA reveals clusters of data \u2013 though still with zero correlation.",
      "Even if no structure is apparent, reducing the dimensionality of the data can be useful for further analysis. For example, suppose we have data on cancer screening rates in each data SIMD zone, we could then do multiple regression of the cancer screening rate on the new deprivation and remoteness variables. This is probably going to give us coe\ufb03cients that are a lot more interpretable than regressing on all 26 variables.",
      "Projecting principal component scores back into the data space (EXTRA \u2013 not in video) Sup- pose we have identi\ufb01ed the \ufb01rst two principal component scores ti1 and ti2 of area i. We might wish to project them back into the data space, to see what the original variables looked like. To do this we can use the following equations to give approximations (indicated by the tilde) to the original standardised",
      "4",
      "1050510PC110.07.55.02.50.02.55.07.510.0PC2Unemploymentovercrowded_rateAttendancedrive_retaildrive_secondary\fvariables:  \u02dczi1 = p11ti1 + p12ti2 \u02dczi2 = p21ti1 + p22ti2  ...  \u02dcziD = pD1ti1 + pD2ti2  (2)",
      "We can include more terms for higher PCs, right up to the Dth PC. In general, the jth component of the i data point is given:  zi j = p j1ti1 + p j2ti2 + . . . p jDtiD  =",
      "D(cid:88)  k=1  p jktik  (3)",
      "Once we\u2019ve got the standardised variables, we can convert back to the original variables using the formula xi j = zi js j + x j.",
      "Principal component equations in vector notation (EXTRA \u2013 not in video) The equations used so far may make more sense when expressed as vectors. The jth principal component is actually a vector of length 1 in the original data space:  p j = (p1 j, p2 j, . . . , pD j)T  (4)",
      "All the principal component vectors are orthogonal to each other. With this notation we can write Equation 2 as a linear combination of the principal component vectors, weighted by the principal component scores:  zi = ti1p1 + ti2p2 + . . .  (5)",
      "The dots indicate that we could go up to tiDpD. We can rewrite Equation 1, in which we computed the scores, as the scalar product of the ith standard- ised data point and the jth principal component:  ti j = zi \u00b7 p j  (6)",
      "We\u2019ll extend this notation to matrix notation in the derivation.",
      "2 Video: Principle of \ufb01nding principal components",
      "A 2D example We\u2019ll now discuss the principle of how to determine the principal components with an imaginary 2D example. Suppose we ask if is there are di\ufb00erent types of Informatics students, perhaps based on their preferences for programming languages and for drinks. We ask students if they prefer, on a scale of 1\u20139, Haskell (1) to Java (9), and if they prefer Tea (1) to Co\ufb00ee (9), and \ufb01nd the data in Table 2.",
      "Plotting the data (Figure 3 left) shows that students\u2019 preferences for drinks and programming languages are correlated. It seems that we could characterise every Informatics student by one number that is low if they like Haskell and tea, and high if they like Java and co\ufb00ee. If we could rotate the axes (Figure 3 right), the new x-axis would give us this number.",
      "5  \fTable 2: Imaginary data about Informatics students\u2019 preferences for programming languages and drinks.",
      "Student ID Language Drink 8 1 1 2 7 3 2 4 3 5 6 6 3 7 8 8 2 9 7 10",
      "9 3 8 2 3 8 2 8 1 6",
      "Figure 3: Informatics students\u2019 preferences for drinks and programming languages, as plotted initially (left), and rotated (right).",
      "6  llllllllll24682468Haskell         No pref.         JavaTea             No pref.         Coffeellllllllll24682468Haskell         No pref.         JavaTea             No pref.         Coffee\f1. Change the angle we view the data from to see things clearly",
      "2. Ignore small details in the data that don\u2019t a\ufb00ect the big picture",
      "Figure 4: Visualisation of how PCA achieves the two objectives in the text.",
      "Once we\u2019ve done the rotation (changed the angle), we end up with the data plotted against a new set of axes, which are the principal components (Figure 4, top). The new x-axis, which tells us a lot about the students\u2019 preferences for Java and co\ufb00ee or tea and Haskell, is the \ufb01rst principal component (PC1). The new y axis is the second principal component (PC2). It is worth noting two points:  \u2022 The correlation between the new PC1 and PC2 scores is zero. It is a general property of PCA  that correlations between scores is zero.  \u2022 We have not lost any information about the data; we can reconstruct the original data by reversing the rotation. It is a general property of PCA that it is possible to reconstruct the data if scores of all D principal components are retained.",
      "The second principal component doesn\u2019t seem so informative, so we could just ignore it altogether (Figure 4, bottom). Thus, we have ignored small details in the data that don\u2019t a\ufb00ect the big picture. We have performed dimensionality reduction by reducing the number of values describing each data point from two to one.",
      "Objective of rotation There are two questions that we haven\u2019t answered so far:",
      "1. How do we choose how much to rotate the axes?",
      "2. What counts as \u201cinformative\u201d?",
      "The answer to both questions is \u201cvariance\u201d. In Figure 4 (top), the variance of the data in the PC1 direction is much greater than the variance of the data in the PC2 direction. The high variance PC1 is",
      "7  llllllllll24682468Haskell         No pref.         JavaTea             No pref.         Coffeel\u22126\u22124\u221220246\u22126\u22124\u221220246PC 1PC 2llllllllllllllllllll\u22124\u22122024\u22124\u22122024Haskell         No pref.         JavaTea             No pref.         Coffeel\u22126\u22124\u221220246PC 1llllllllll\fFigure 5: Scree plot for PCA applied to SIMD example (left). The elbow (or knee) is indicated in red. The Cumulative scree plot (right).  telling us a lot about the informatics students, whereas the low variance PC2 tells us little. Therefore, in order to choose how to rotate the axes, we use the variance as an objective. In fact there are two ways of formulating PCA:",
      "1. Maximum variance formulation: \ufb01nd an axis that maximises the variance of the data projected  onto it",
      "2. Minimum variance formulation: \ufb01nd an axis that minimises the variance of the data projected  onto it",
      "It doesn\u2019t matter which formulation we use; the answer is the same either way.",
      "Explained variance The variance in the original x (Programming language) and y (Drink) directions was 9.7 and 7.7. The sum of these two variances is the total variance, i.e. 17.4. It turns out that the sum of the variance along the principal components is exactly the same. However, the variance of the PC1 scores is 16.5, i.e. 96% of the total variance. We therefore say the PC1 explains 96% of the variance.",
      "More than 2D In general, we can \ufb01nd D principal components in D dimensions. The principal components are all orthogonal to each other, and each principal component explains a certain fraction of the variance. We order the principal components from the one that explains most variance to the one that explains least.",
      "In the SIMD example, the \ufb01rst principal component explains 41.7% of the data and the second explains a further 15.2%. Thus, the \ufb01rst two principal components together explain 56.9% of the variance. We can visualise how much each principal component explains in a scree plot or cumulative scree plot (Figure 5).",
      "How many components to choose? Obviously if we are visualising data, we can only look straight- forwardly at up to 3 dimensions. The scree plot helps us to choose how many components to include if we are using PCA as a preprocessing step. A rule of thumb is to use the components to the left of",
      "8",
      "01020PC010203040% variance explainedElbow or Knee01020PC020406080100Cumulative % variance explained\fTable 3: Coe\ufb03cient of determination and adjusted coe\ufb03cient of determination for regression of grades on original variables and on 2 or 4 PC scores.",
      "4 Original variables 0.289 0.251",
      "4 PC scores 2 PC scores 0.282 0.263",
      "0.289 0.251",
      "R2 R2 a  the \u201cknee\u201d or \u201celbow\u201d of the scree plot, i.e. the point where the gradient changes sharply. In Figure 5 this point is indicated in red, and the rule of thumb would suggest that we use PC1 and PC2. There are more principled ways of choosing, which we won\u2019t cover at this point, and it may also be that successful application of PCA requires more components.",
      "In the next video, we\u2019ll look at the maths of how to \ufb01nd the directions of the principal components and the associated variances. However, you should already know enough to skip to the video after, which is about applying PCA to help with a regression problem.",
      "3 Video: PCA and regression",
      "PCA as preprocessing PCA is often used as a preprocessing step before another method, e.g. linear regression or K-means. Here we\u2019ll see how it can help simplify the grades example from the linear regression lecture. Figure 6 shows the results of applying PCA to the independent variables in this example. Note the correlations between the PC scores are all zero; the general property of PCA already mentioned. However, the correlations between the PC scores and the Grade are non-zero. We can regress the Grade y on the principal component scores t(1), t(2) . . . :  y = \u02c6\u03b20 + \u02c6\u03b21t(1) + \u02c6\u03b22t(2) + . . .  (7)",
      "When we regress on all 4 PC scores, we get exactly the same predictions and coe\ufb03cient of determi- nation as we do for regressing on all variables (Table 3). This makes sense, since by keeping all 4 components we have not lost any information about the data. It is more surprising that the coe\ufb03cient of determination with if we regress on only the \ufb01rst two PC scores is almost as high. Furthermore, the adjusted coe\ufb03cient of determination is actually higher when regression on the \ufb01rst two principal components, due to there being fewer variables. There is no combination of any two of the original variables that gives as high a coe\ufb03cient of determination. This example demonstrates that PCA can be a useful preprocessing step for regression, by decorrelating the variables.",
      "PCA and linear regression lines Thinking back to linear regression, we remember the distinction between the regression lines of y on x and x on y. In two dimensions there is now a 3rd line: the \ufb01rst principal component. This goes right between the regression lines, and is probably what you would think the line of best \ufb01t to the data is. In fact, it is a line of best \ufb01t. It\u2019s the line that minimises the sum of the squared distances from the data points to the line, rather than minimising the error in predicting y or x.",
      "4 Video: Derivation of PCA",
      "Overview of derivation Here are the steps we\u2019ll take in our derivation:",
      "9  \fFigure 6: PCA scores of independent variables in Grades example (see Multiple regression lecture notes).",
      "10",
      "2.50.02.5PC1202PC220PC302PC42.50.02.5PC16080100Grade0.02.5PC22.50.0PC302PC450100Grade\fFigure 7: Regression of y on x, x on y and the \ufb01rst principal component of data with a correlation coe\ufb03cient r = 0.5.",
      "1. De\ufb01ne variance along the original axes",
      "2. Project data onto rotated axes",
      "3. Compute variance in these axes",
      "4. Find direction of the axis that maximises variance of data projected onto it (1st principal  component, PC 1)",
      "5. Interpret",
      "6. Find the 2nd principal component (PC 2)",
      "7. Quantify what is lost by dimensionality reduction",
      "De\ufb01ning variance along original axes We\u2019ve already met a lot of the mathematical machinery we need in the multiple regression topic. We\u2019ll assume now that we have D variables x(1), . . . , x(D), and = xi j \u2212 x( j). Usually, as in the SIMD that we have de\ufb01ned zero-mean versions of the variables x\u2217 i j example, we start o\ufb00 with standardised variables anyway. We can arrange these zero-mean variables in an n \u00d7 D matrix,",
      "X =  \uf8eb  \uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed  x\u2217 11 ... x\u2217 n1  \u00b7 \u00b7 \u00b7 x\u2217 1D ... \u00b7 \u00b7 \u00b7 x\u2217 nD  \uf8f6  \uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8  \uf8eb  \uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed  xT 1 ... xT n  \uf8f6  \uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8  = (cid:16)  x(1)  \u00b7 \u00b7 \u00b7 x(D) (cid:17) =  (8)  which it can be helpful to write in terms of the D n \u00d7 1 vectors representing all the data in each dimension, or as the transposes of the n D \u00d7 1 vectors representing each data point. We\u2019ve also met the covariance matrix, the D \u00d7 D matrix that\u2019s derived from the data matrix:",
      "S =  \uf8eb  \uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed  s11 ... sD1  \u00b7 \u00b7 \u00b7  \u00b7 \u00b7 \u00b7  \uf8f6  \uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8  s1D ... sDD  = 1  n \u2212 1",
      "XT X",
      "11  (9)",
      "21012x21012yy on xx on yPC1\fFigure 8: Projection of a data point x onto a unit vector p.",
      "The variance in the original axes is s11 and 22. The covariance matrix in our toy example is:  (cid:32)",
      "S =  (cid:33)",
      "9.7 8.0 8.0 7.7",
      "Step 2: Project data onto a new axis We\u2019ll de\ufb01ne the new axis by the unit vector p (Figure 8). The projection of a data point xi onto this axis (its component score) is (as per Equation 1)  ti = pT xi = p1xi1 + p2xi2",
      "Step 3: Compute variance in these axes The de\ufb01nition of the variance of the t(1) is:",
      "If we substitute Equation 10 into this equation we get the following:  s2 t  = 1  n \u2212 1  n(cid:88)  i=1  t2 i  n(cid:88)  (p1xi1 + p2xi2)2  i=1 n(cid:88)  i=1  (p1 p2)  (cid:32) (cid:80) (cid:80)  i xi1xx1 i xi2xx1  (cid:80) (cid:80)  i xi1xx2 i xi2xx2  (cid:33)  (cid:32)  =  (cid:33)  p1 p2  s2 t  = 1  n \u2212 1  = 1  n \u2212 1 = pT Sp  (10)  (11)  (12)",
      "Our old friend the covariance matrix has reappeared. Although we\u2019ve demonstrated this in 2 dimensions, the equation is still valid in D dimension.",
      "Step 4: Find direction of axis that maximises variance of data projected onto it (1st principal component, PC 1) We now have an expression for the variance in the component scores for any direction of p we now want to \ufb01nd the direction of p that maximises that variance. We have a constraint that p is of unit length, so |p| = 1. This is a constrained optimisation problem, which we can solve using Lagrange multipliers and di\ufb00erentiation. We won\u2019t show the details here, but the result is the following equation:",
      "Hopefully you recognise this equation. Its solutions are:",
      "Sp = \u03bbp",
      "12  llllllllll\u22124\u22122024\u22124\u22122024Haskell         No pref.         JavaTea             No pref.         Coffeelxlt1p\u22126\u22124\u221220246t(1)lllllllllll\fFigure 9: Projection into the original space.",
      "1. \u03bb = \u03bb1, p = e1, where \u03bb1 is the biggest eigenvalue of S and e1 is the associated eigenvector 2. \u03bb = \u03bb2, p = e2, where \u03bb2 is the second biggest eigenvalue of S and e2 is the associated  eigenvector",
      "We choose the \ufb01rst principal component p1 to be the eigenvector e1 with the largest eigenvalue \u03bb1. \u03bb1 is the variance of the 1st component scores t(1).",
      "Step 5: Interpret Finding the eigenvalues and eigenvectors for our example, we arrive at the \ufb01rst principal component being:  p1 =  (cid:32)  (cid:33)",
      "0.75 0.66",
      "Java Co\ufb00ee  \u03bb1 = s2 t(1)  = pT",
      "1 Sp1 = 16.5",
      "The \ufb01rst component score t(1) is the \u201cJava-co\ufb00eeness\u201d of a student.",
      "Step 6: Find the 2nd principal component (PC 2) In 2D our job is already done, since there is only one direction perpendicular to p1, and eigenvectors (and therefore principal components) are always orthogonal to each other. It\u2019s the other eigenvector of S, p2 = e2, with eigenvalue \u03bb2, which is the variance of the 2nd component scores t(2). In D dimensions, the principal components are the D eigenvectors of the D \u00d7 D matrix S. It\u2019s helpful to introduce more matrix notation here. We arrange the principal components in the rotation matrix:",
      "P = (cid:16)  p1 p2  (cid:17)",
      "Step 7: Quantify what is lost by dimensionality reduction We can reverse the transformation from the scores to the original data",
      "X = TPT If we drop the 2nd PC from P and the 2nd PC scores from T, we can reconstruct a 1-dimensional version of the original data:  \u02dcX(1) = t(1)pT 1",
      "We can see (Figure 9) that the \ufb01rst principal component (the \u201cJava-co\ufb00eeness\u201d) score of a student tells us a lot about them \u2013 but how much? Consider the total variance, the sum of the variances of the data:",
      "D(cid:88)  i=1  =  s2 i",
      "D(cid:88)  i=1  \u03bbi",
      "13  llllllllll\u22122024\u22122024Haskell         No pref.         JavaTea             No pref.         Coffeel\u22126\u22124\u221220246t(1) (PC 1)llllllllll\fIt is equal to the sum of the eigenvalues of the covariance matrix. Thus the fraction of the total variance \u201cexplained\u201d by the ith principal component is:",
      "In our toy example,  \u03bbi (cid:80)D j=1 \u03bb j  \u03bb1 \u03bb1 + \u03bb2  =",
      "16.5 16.5 + 0.61  = 96%",
      "Thus we can now be more precise about how much the \ufb01rst principal component (the \u201cJava-co\ufb00eeness\u201d) score of a student tells us about them: 96% of of the variance.",
      "14  \fReferences",
      "Scottish Government  \u2018Scottish index of multiple deprivation (SIMD) 2016\u2019. https:\/\/www.webarchive.org.uk\/wayback\/archive\/20200117165925\/https:  (2016).",
      "URL \/\/www2.gov.scot\/SIMD",
      "15"
    ]
  },
  "1": {
    "title": "FDS-S1-09-1-intro-supervised-learning",
    "content": [
      "Inf2 \u2013 Foundations of Data Science 2021 Topic: Intro to supervised learning: training, testing and validation: Nearest neighbours",
      "Hiroshi Shimodaira*, Iain Murray*, David C. Sterratt",
      "14th November 2021",
      "Further reading (not examinable): Hastie et al. (2009) pp 463\u2013471",
      "1 Video: Classi\ufb01cation",
      "Supervised learning of classi\ufb01cations Suppose a bank has data on previous customers it has given loans to, including variables such as their income, housing status and employment status. Each of these sets of variables \u2013 also referred to as feature vectors \u2013 has a label, indicating whether the customer did or didn\u2019t pay back their loan. The bank might want to predict whether a new customer will be able pay back a bank loan from their features, i.e. to predict whether they belong to the class of customers who paid or the class of customers who didn\u2019t pay. This is an example of the classi\ufb01cation problem, which we de\ufb01ne as the problem of predicting the correct label for an unlabelled input feature vector.",
      "Supervised and unsupervised learning Classi\ufb01cation is an example of a supervised learning pro- cess. In a supervised learning process, there is a training set of data in which each data item has a number of features and a known label. The goal of supervised learning is to predict the label of an item that has not been previously seen from its features. In contrast, in unsupervised learning processes, the training set does not contain any labels, and the goal is to learn something about the structure of the data. We will return to unsupervised learning in a later topic.",
      "Visualising the classi\ufb01cation problem To visualise the classi\ufb01cation problem, we\u2019ll use a toy example: the fruit data set, collected by Iain Murray (Murray, 2006). He bought pieces of fruit and measured their height and width (features) and noted the type of fruit (the label). Figure 1 visualises  *These lecture notes are based on the ones written by Iain Murray and Hiroshi Shimodaira for the Inf2B course, which  ran until the academic year 2019\/20.",
      "1  \fFigure 1: The supervised learning problem, as applied to fruit. We are given the labels of the fruit with various widths and heights. We are then presented with an unknown piece of fruit with given width and height (the test point, represented by the question mark). The task is then to predict what type of fruit it is.  the data. In the context of the fruit, the classi\ufb01cation problem is using this dataset to build a machine to predict the class of a piece of unidenti\ufb01ed fruit automatically just by measuring its width and height. We will refer to the feature vector of this unidenti\ufb01ed fruit as the test point.",
      "De\ufb01nition of a classi\ufb01er To solve a speci\ufb01c classi\ufb01cation problem, we construct a classi\ufb01er. A classi\ufb01er is a function that takes a feature vector x and returns a class c where c is a member of a set C. In principle, we can construct a classi\ufb01er however we want to, as long as it matches this de\ufb01nition. Regardless of how the classi\ufb01er is constructed, it will have two important properties: decision boundaries and classi\ufb01cation errors.",
      "Decision boundaries Consider the problem of determining apples from pears. In this example case we have two features for each piece of fruit: its circumference (at the widest point) and its height, each measured in cm. Apples are \u2018more spherical\u2019 than pears which tend to be longer than they are wide. But some pears are relatively short and some apples are taller than expected. In this case we have an input vector of the form x = (x(1), x(2))T , where x(1) is the circumference and x(2) the height. The class c can take two values A or P (standing for apples and pears).",
      "We have a set of training data: height and circumference measurements, along with class labels. In Figure 2 we plot this two-dimensional training data for the two classes. We can see that it is not possible to draw a straight line to separate the two classes.",
      "We now have three new, unlabelled examples which we would like to classify (represented as stars in Figure 3):",
      "2",
      "246810Width (cm)45678910Height (cm)?FruitAppleMandarinBig OrangeOrangeLemon\fFigure 2: Training data for apples and pears. It is not possible to draw a straight line to perfectly separate the classes in this feature space. Three possible lines are drawn, but each results in a number of misclassi\ufb01cations.  \u2022 (16, 10): all the training data in the region of this point is classi\ufb01ed as P, so we classify this point  as P.  \u2022 (19, 6): looking at the training data it seems obvious to class this as A.  \u2022 (18, 7): it\u2019s not obvious in which class this example should be classi\ufb01ed; the feature vector gives us evidence whether we have an apple or a pear, but does not enable us to make an unambiguous classi\ufb01cation.",
      "We can draw a straight line such that one side of it corresponds to one class and the other side to the other \u2013 as in the three possible lines shown in Figure 2. Such a line is called a decision boundary; if the data was three-dimensional, then the decision boundary would be de\ufb01ned by a plane. For one-dimensional data, a decision boundary can simply be a point on the real line. Intuitively it seems possible to \ufb01nd an optimal decision boundary, based on minimising the number of misclassi\ufb01cations in the training set.",
      "Constructing classi\ufb01ers using supervised learning To construct the classi\ufb01er automatically we need:",
      "1. a set of training data containing feature vectors and their labels",
      "2. an algorithm that we train using the training data",
      "3",
      "1051520Circumference\/cmHeight\/cmpearsapples\fFigure 3: The training data for apples and pears, together with three test points.",
      "3. hyperparameters, numbers that control how the algorithm learns and predicts",
      "This is referred to as supervised learning, since the label for a training vector acts as supervision for the classi\ufb01er when it is learning from training data.",
      "Regression as supervised learning We have already encountered another form of supervised learn- ing: linear regression. Here the independent variables are synonymous with feature vectors. Rather than being associated with a label, a categorical variable, the independent variables are associated with the dependent variable, which is a numeric variable. However, the task is still to predict a value of this \u201clabel\u201d for an unseen value of the independent variable, and we \u201ctrain\u201d linear regression by computing the best estimates for the coe\ufb03cients from existing data.",
      "2 Video: Nearest neighbour classi\ufb01cation",
      "Principle of nearest neighbour classi\ufb01cation Nearest neighbour classi\ufb01cation (or one-nearest neighbour classi\ufb01cation to be precise) has a very simple basis: to classify a test item, \ufb01nd the item in the training set which is closest and assign the test item to the same class as the selected training item. If there happens to be an identical item in the training set then it makes sense to assign the test item to the same class. Otherwise, the class of the member in the training set which is most similar to the test item is our best guess. We use a distance measure (e.g., Euclidean distance) to determine similarity. If we have a representation for which the distance measure is a reasonable measure of similarity, then the nearest neighbour method will work well.",
      "4",
      "1051520Circumference\/cmHeight\/cm\fDecision boundaries for nearest neighbour classi\ufb01cation What do the decision boundaries look like for nearest neighbour classi\ufb01cation? Each training data point de\ufb01nes a region around it; test points within this region will be classi\ufb01ed to the same class as the training data point. These regions are illustrated for a simple case in Figure 4, where the boundaries of regions are shown as dotted lines. Each boundary is given as the perpendicular bisector of the line segment between the two corresponding data points. This partitioning formed by a set of data points is sometimes called Voronoi diagram or Voronoi tessellation.",
      "Figure 4: Decision boundaries by 1-NN for data points of distinct classes from each other",
      "Now we assume that each data point belongs to either of two classes, say, red or blue. To obtain the decision boundary we combine those boundaries which are between regions of di\ufb00erent classes, as illustrated in Figure 5. The resultant boundary is referred to as being piecewise linear. Figure 6 shows the decision boundary and decision regions in the case of three classes.",
      "Application of 1-nearest neighbour to a real dataset Figure 7 shows 1 nearest-neighbour classi\ufb01- cation applied to the fruit dataset. Note that we\u2019ve standardised the variables, so that the data spreads out roughly equally in both directions. In common with other distance-based methods, we would like the results of clustering to be independent of the units we measure the variables in. It can be seen that the decision boundary is quite complex, with islands of apple amongst the oranges. We\u2019ll explore in the next video if this might be a problem.",
      "3 Video: Evaluation",
      "Classi\ufb01cation error function When we discussed linear regression, we evaluated its performance by an error function, such as the root mean squared error, which was a function of the actual and predicted values yi and \u02c6yi. A suitable error function for classi\ufb01cation is the number of items that are misclassi\ufb01ed \u2013 i.e., the number of times the classi\ufb01er assigns a class label \u02c6ci di\ufb00erent from the true class label ci. The classi\ufb01cation",
      "5",
      "01234567012345\fFigure 5: Decision boundary and decision regions for a 1-nearest neighbour classi\ufb01er for a training data set of two classes, where training samples of one class are shown with \u2018*\u2019 in red, those of the other class are shown with \u2018\u25e6\u2019 in blue. The Euclidean distance is used as the distance measure in this example.",
      "Figure 6: Decision boundary and decision regions for a 1-nearest neighbour classi\ufb01er for three classes.  error is often expressed as the percentage of the total number of items that is misclassi\ufb01ed, the error rate.",
      "6",
      "0123456701234501234567012345\fFigure 7: Decision regions for one nearest neighbour classi\ufb01cation applied to the fruit data set. The variables have been standardised to make the scales on both axes similar. Some regions are darker shade of blue or red. This indicates that there are 2 points labelled with \u201capple\u201d or \u201corange\u201d in the dataset with the same features. There is one region that is purple, amongst the blue and red region. There are two data points corresponding to this region with identical coordinates, one labelled with orange and one with apple.",
      "7",
      "3210123Width3210123Height\fError function for one-nearest neighbour classi\ufb01cation For one-nearest neighbour classi\ufb01cation, the error rate when we consider members of the training set is 0, since the closest point in the training set to a member of the training set is itself1.",
      "Evaluating generalisation to unseen data This sounds very promising, until we remember that the job of the classi\ufb01er is to classify data points that we haven\u2019t seen before. It may be that the classi\ufb01er will not generalise to data that haven\u2019t seen. In order to estimate how well the classi\ufb01er generalises, we can split our original data set into a training set and a testing set. The training and testing sets are mutually exclusive, and a typical split might be 70% for training and 30% for testing. We train the classi\ufb01er using the training set, and then evaluate the performance using the testing set. We are not allowed to use the test set to train the classi\ufb01er \u2013 otherwise our estimate of its performance on the test set will be too optimistic.",
      "In summary, the training set error rate is the percentage of misclassi\ufb01cations that the classi\ufb01er makes on the training set after the learning algorithm has been applied. The test set error rate refers to errors made by the classi\ufb01er on the testing set.2",
      "Training and testing set notation We\u2019ll use the notation: x = (x(1), x(2), . . . , x(D))T to denote a D-dimensional (input) feature vector, which has class label c. The training set is a set of n feature vectors and their class labels; the i\u2019th training item consists of a feature vector xi and its class label ci. The j\u2019th element of the i\u2019th feature vector is written xi j.",
      "4 Video: k-Nearest neighbour classi\ufb01cation",
      "Principle of k-nearest neighbour classi\ufb01cation Rather than just using the single closest point, the k-nearest neighbour approach looks at the k points in the training set that are closest to the test point; the test point is classi\ufb01ed according to the class to which the majority of the k-nearest neighbours belong. For the \ufb01rst two items above, the value of k is not really important: (16, 10) is classi\ufb01ed as P and (19, 6) is classi\ufb01ed as A, no matter how many nearest neighbours are considered. However, the third example above, (18, 7), is ambiguous, and this is re\ufb02ected in the sensitivity of the classi\ufb01er to the value of k:  \u2022 1-nearest: classi\ufb01ed as pear  \u2022 2-nearest: tie (one apple and one pair are nearest neighbours). In this case, just choose randomly  between the two classes  \u2022 3-nearest: classi\ufb01ed as apple  \u2022 5-nearest: classi\ufb01ed as pear  \u2022 9-nearest: classi\ufb01ed as apple 1Unless we have two data points with exactly the same features and di\ufb00erent labels. 2The technique of using separate data sets for training and testing is referred to as cross validation.",
      "8  \fFigure 8: Decision regions, training error and testing error for various values of k.",
      "Decision boundaries produced by k-NN classi\ufb01cation k-nearest neighbour classi\ufb01ers make their decisions on the basis of local information. Rather than trying to draw decision boundaries across the whole space (as in Figure 2), k-nearest neighbour techniques make decisions based on a few local points. As such they can be quite susceptible to noise, especially if k is small: a small shift in the location of a test point can result in a di\ufb00erent classi\ufb01cation since a new point from the training data set becomes the nearest neighbour. As k becomes larger, the classi\ufb01cation decision boundary becomes smoother since several training points contribute to the classi\ufb01cation decision (Figure 8).  k-nearest neighbour algorithm We can write the k-nearest neighbour algorithm precisely as follows, where and d is the distance metric (typically the Euclidean distance):  \u2022 For an unseen example x:  \u2013 Compute the n distances di = d(x, xi) between x and the features of each training example  xi, i \u2208 1, . . . n.  \u2013 Sort the distances from lowest to highest and \ufb01nd the indices i1, . . . ik of the k lowest values  of di  \u2013 Find the classes that belong to the closest points, i.e. ci1, . . . , cik \u2013 Each of these represents a vote for a class. Count the votes for each class and return the  one with the largest number.  \u2013 If there is a tie, choose randomly, or look at the k + 1th neighbour to resolve the tie.",
      "9  \fFigure 9: Classi\ufb01cation error rate for various values of k.",
      "Choosing k The value k is hyperparameter: a number that we can choose to get the best perfor- mance from the algorithm. Figure 8 shows the classi\ufb01cation error for various values of k on the training set and the testing set. As k increases the error on the training set initially increases rapidly, as explained in the last video. The testing error decreases a little and then starts rising around k = 9, indicating that a somewhat larger k helps generalisation. Both testing and training error then increase.",
      "This graph suggests that we can look at the error on the testing set to set k. But this would break the rule of using the test data to train the classi\ufb01er, since our choosing the best hyperparameter k is part of the training process. We have really been using the test data validation data, that is, data used to help us validate our choice of hyperparameter.",
      "Thus, we need to divide our dataset into 3 parts:  \u2022 Training data (about 50%): used to train the classi\ufb01er for any particular value of k.  \u2022 Validation data (about 25%): used to compare performance of the trained classi\ufb01er for di\ufb00erent  values of k.  \u2022 Testing data (about 25%): used to assess the performance of the trained classi\ufb01er with the one  value of k that we have chosen.",
      "The precise fractions of data are not crucial. There are more sophisticated ways of undertaking validation that we won\u2019t go into here.",
      "Computational e\ufb03ciency of k-nearest neighbour classi\ufb01cation k-nearest neighbour is very e\ufb03- cient at training time, since training simply consists of storing the training set.3 Testing is much slower, since, in the simplest implementation, it would involve measuring the distance between the test point and every training point, which can make k-nearest neighbour impractical for large data sets.",
      "3In practice, responsible machine learning practitioners will try out di\ufb00erent choices of k, and di\ufb00erent distance measures, possibly optimising free parameters of a distance measure. Then training requires testing di\ufb00erent choices, and becomes expensive.",
      "10",
      "02040k0.000.050.100.150.200.25Classification error rateE_trainE_test\fImproving the e\ufb03ciency of k-NN It is sometimes possible to store the training data set in a data structure that enables the nearest neighbours to be found e\ufb03ciently, without needing to compare with every training data point (in the average case). One such data structure is the k-d tree. However, these approaches are usually only fast in practice with fairly low-dimensional feature vectors, or if approximations are made.",
      "References",
      "Hastie, T., Tibshirani, R. et al. (2009). The elements of statistical learning. Springer, second ed. URL  http:\/\/dx.doi.org\/10.1007\/b94608",
      "Murray, I. (2006). \u2018Oranges, lemons and apples dataset\u2019. URL http:\/\/homepages.inf.ed.ac.uk\/  imurray2\/teaching\/oranges_and_lemons\/",
      "11"
    ]
  },
  "2": {
    "title": "FDS-S1-10-1-randomness-simulation-sampling",
    "content": [
      "Inf2 \u2013 Foundations of Data Science 2021 Topic: Randomness, sampling and simulation",
      "David C. Sterratt",
      "20th November 2021",
      "Recommended reading:  \u2022 Computational and Inferential Thinking, Chapter 9  \u2022 Computational and Inferential Thinking, Chapter 10  \u2022 Computational and Inferential Thinking, Chapter 14  \u2022 Modern Mathematical Statistics with Applications, Sections 6.1 and 6.2",
      "1 Video: Introduction to statistical inference",
      "Statistics The German word Statistik arose in the 18th century and originally referred to \u201cdata about the state\u201d (country). The \ufb01rst use of \u201cstatistical\u201d in the English language was in 1791 in the Statistical Account of Scotland. Sir John Sinclair, an elder in the Church of Scotland, sent a questionnaire to ministers in every parish (church district) in Scotland. The questionnaire asked many questions about agriculture, industry, economics, employment, poverty and education, as well as \u201cThe state of the manners, the morals, and the religious principles of the people\u201d. In fact empires and dynasties have been collecting data about population and trade for much longer than this, going back to the Han dynasty in China and the Roman Empire.",
      "Inferential statistics This use of the word statistics above relates to the whole population. In contrast, back in the topic on Statistical Preliminaries, we looked at the di\ufb00erence between a sample and a population. We also considered a number of statistics that could apply to the population and to the sample: the mean, variance, standard deviation and median. Inferential statistics is the process of drawing conclusions about quantities that are not observed (Gelman et al., 2004).",
      "1  \fFigure 1: Uncertainty in regression line. The best estimate regression line (solid) and the lines at the edge of the 95% con\ufb01dence interval (dashed lines). Note this plot is simpli\ufb01ed, since the uncertainty in the intercept is not represented.",
      "One example of an inferential statistics task is estimation of a population statistic from a sample of that population. For example, suppose we\u2019ve weighed a sample of 10 wild cats from a population of 400. We know what the sample mean and sample standard deviation is. On the basis of this information, what is the best estimate of the population mean (point estimation), and how con\ufb01dent can we be in that estimate (con\ufb01dence interval estimation)?",
      "Inferential statistics has been around for much longer than the word \u201cstatistics\u201d. The 9th-century book \u201cManuscript on Deciphering Cryptographic Messages\u201d written in Arabic by Al-Kindi (educated in Baghdad) shows how to decipher encrypted messages by frequency analysis, i.e. counting the frequency of particular letters.",
      "Inferential statistics tasks Inferential statistics can seem like a toolbox full of tools with confusing names such as \u201cstandard error of the mean\u201d, t-test, \u03c72 test, bootstrap, and a confusing set of rules about what to use each tool for. We\u2019re going to try to give you an idea of what task each tool is useful for, and how it works. There are three main tasks we will consider:",
      "1. Estimation",
      "2. Hypothesis testing",
      "3. Comparing two samples (A\/B testing)",
      "Estimation We\u2019ve already given one example of estimating an unobserved quantity (the population mean). Another example of an unobserved quantity is linear regression coe\ufb03cients. We already know how to \ufb01nd (point) estimates of them, using the formulae we covered earlier in the course. But in part of the course we will learn how to estimate the con\ufb01dence intervals around the point estimates, which will tell us how much uncertainty there is in our estimates. For example, we\u2019ll be able to say that we estimate the mean weight of squirrels in the population to be 320 \u00b1 16g, with 95% con\ufb01dence, i.e. in the con\ufb01dence interval [304, 336]g. In a linear regression of the weight of a sample of squirrels on their length (Figure 1), we will be able to say that the best estimate of the slope of the regression line is 3.35 g\/mm, but we are 95% con\ufb01dent that the slope lies in the interval [2.32, 4.38] g\/mm.",
      "2",
      "210220230Length (mm)300350400Weight (g)\fHypothesis testing In hypothesis testing, we are trying to ascertain which of two or more competing theories are the best explanation of the data. For example, in 1965 a court case was brought against the state of Alabama (Swain versus Alabama, 1965) due to there being no Black members of the jury in a trial. Part of the case concerned the fact that at one stage of the jury selection, 8 Black people were chosen for a jury panel of 100 people, but the fraction of Black people in the population was 26%. Our question is \u201cIs the jury selection system biased against Black people?\u201d.",
      "Comparing two samples (also known as A\/B testing) Here we have two samples that have been treated di\ufb00erently, and we want to either test if the groups are di\ufb00erent, or estimate how di\ufb00erent they are. For example, to \ufb01nd out the e\ufb00ectiveness of a vaccine, we select a sample of volunteers from the population randomly, divide them randomly into two groups, give the vaccine to one group (Treatment group) and give the other group a placebo (Control Group). In the vaccine group 3 volunteers catch the disease, but in the placebo group 95 volunteers catch the disease. Is the vaccine e\ufb00ective? How much would we expect the vaccine to cut the risk of catching the disease if we give it to the whole population? In the context of user testing, often in web applications, this is called A\/B testing. A famous example was at Amazon, where a developer had the idea of presenting recommendations as you add items to a shopping cart (Kohavi et al., 2007). Amazon managers forbid the developer to work on the idea, but the developer disobeyed orders and ran a controlled experiment on users, by splitting them into two groups (\u201cA\u201d and \u201cB\u201d), one which had recommendations shown and one which didn\u2019t. The group which had recommendations shown bought more, and displaying recommendations quickly became a priority for Amazon.",
      "Two approaches to statistical inference We are going to learn a number of techniques for under- taking point and interval estimation, hypothesis testing and comparing samples. We will also think carefully about the interpretation of these techniques. There are two main approaches to undertaking statistical inference tasks:",
      "1. Statistical simulations. Here we use repeated random sampling to carry out the statistical inference procedures. The advantages of statistical simulation procedures are they often require fewer assumptions about the data and\/or hypothesis, and they require somewhat less theory to understand. However, they can be compute-intensive, and care is still needed in their use.",
      "2. Statistical theory.. Here we use the properties of various well-known theoretical distributions to draw inferences about our data. We need to check that the assumptions behind the distribution match the statistical question we are trying to answer. For example, a distribution of delays to \ufb02ights is likely to be highly right-skewed, so we shouldn\u2019t assume a normal distribution when dealing with it. Typically, the process is not compute-intensive: very often it amounts to arithmetic and then reading of a quantity from a distribution table. These procedures come as standard in a number of stats packages, including R and Python\u2019s statsmodels.",
      "A number of fundamental concepts underpin both the statistical theory and statistical simulations.",
      "Plan for this semester The plan for the statistical inference topics in this semester will be:",
      "1. Fundamental theory (the rest of this topic):  \u2022 We\u2019ll learn how we can use statistical simulations to generate samples from a model and  compute statistics for each of these samples to give a sampling distribution.",
      "3  \fFigure 2: Histograms of 1,000 samples taken from normal, uniform and exponential distributions.  \u2022 Learn about the distribution of the mean of repeated samples from a model. This will lead us to the central limit theorem, which can help us to estimate the uncertainty in our estimate of the mean, i.e. con\ufb01dence intervals, and the law of large numbers, which also helps with estimation.",
      "2. Estimation (next lecture)",
      "3. Hypothesis testing (third lecture)",
      "4. An interlude - Logistic regression (fourth lecture)",
      "5. Comparing two samples with statistical simulations (\ufb01fth lecture)",
      "2 Video: Sampling, statistics and simulations",
      "Sampling A prerequisite for statistical simulations is being able to sample from probability distribu- tions and from sets of discrete items, including observed data.",
      "Random sample In a random sample of size n from either a continuous probability distribution, or a \ufb01nite population of N items the random variables X1, . . . , Xn comprising the sample are all independent and all have the same probability distribution.",
      "Sampling from probability distributions You should be familiar with sampling from random number generation. A standard random number generator produces numbers within an interval (e.g. [0, 1]) with uniform probability for each number, i.e. it samples from a uniform distribution. We can demonstrate the distribution of a standard random number generator by drawing many samples and plotting a histogram (Figure 2). We adapt these functions to sample from any univariate distribution, e.g. a normal distribution or an exponential distribution (Figure 2).",
      "Sampling from a set of discrete items We can also sample from a population of discrete items. We can select n items from a set of N items at random either without replacement or with replacement. If we sample without replacement, it is as though we are pulling items of various types (e.g. coloured balls) at random out of a bag, and not replacing them. We can only sample up to N items, and also, as we remove items from the bag, the probabilities of drawing a particular type (colour) changes. If",
      "4",
      "01x02040FrequencyUniform2.50.02.5x050100FrequencyNormal05x0100200FrequencyExponential\fwe sample with replacement, we put the item back in the bag, before making our next choice \u2013 we can carry on doing this for ever. We could construct an algorithm for random sampling either with or without replacement from a uniform random number generator, but these functions are provided in packages such as numpy.random.choice in Python.",
      "A particular application of sampling from a set of discrete items is creating a sample of a larger data set.",
      "Non-random samples from a population We can also imagine ways of sampling that are not systematically random. For example, we might have a list of the daily takings in a restaurant. We could take the \ufb01rst n days. But suppose that the dataset has been sorted in terms of takings? We would then have days with low takings at the start of the list, so the statistics of the sample would not resemble the statistics of the population. We could try taking every 7th day in the list \u2013 but if the list is in date order we will always be sampling from one day of the week, e.g. Mondays. Random sampling ensures that we don\u2019t have this type of problem.",
      "Samples of convenience When we are collecting data, it might be tempting to sample from the data that we can collect conveniently. For example, a polling company may \ufb01nd it easier to contact people who have more time to answer the phone, which may tend to be retired people. If we don\u2019t correct for this sort of bias, it\u2019s called a sample of convenience. One way of combating convenience sampling is strati\ufb01ed sampling, in which the sampling is targeted so that the proportions of attributes of the sample matches the proportions in the population.",
      "De\ufb01nition of a statistic Before going further, it\u2019s helpful to have the de\ufb01nition of statistic: \u201cA statistic is any quantity whose value can be calculated from sample data.\u201d(Modern Mathematical Statistics with Applications 6). We probably recognise the mean, variance and median as statistics by this de\ufb01nition. But we\u2019ve also derived other quantities from sample data, such as the correlation coe\ufb03cient and regression coe\ufb03cients \u2013 they are also statistics. We will follow Modern Mathematical Statistics with Applications and denote a statistic using an uppercase letter, to indicate that it is a random variable, since its value depends on the particular sample selected. E.g. X represents the mean and S 2 the variance.",
      "Simulations and sampling Before considering inferential statistics proper, we will focus on running statistical simulations, i.e. using a computer program to make predictions from probabilistic models of real-world processes. For example, the probabilistic model of tossing a coin multiple times is that the tosses are independent and that the probability of a head is 1\/2 (or perhaps another value, if with think the coin is loaded). The statistical simulation generates a sequence of heads and tails.",
      "To do this we need to decide on:  \u2022 The statistic of interest (X, S , etc.)  \u2022 The population distribution (e.g. normal with particular mean and variance) or set of discrete  items  \u2022 The sample size (denoted n)  \u2022 The number of replications k",
      "The simulation procedure is then:",
      "5  \fFigure 3: Results of statistical simulations of the panel size in Swain versus Alabama (1965). The blue histogram shows how many of 10 000 simulations produced jury panels of 100 with the given number of Black people on them. The red dot indicates the number of Black jurors in Swain versus Alabama (1965).",
      "1. For i in 1, . . . , k  (a) Sample n items from the population distribution or set of discrete items  (b) Compute and store the statistic of interest for this sample",
      "2. Generate a histogram of the k stored sample statistics",
      "Example of hypothesis testing using a simulation experiment To demonstrate the utility of the statistical experiment we\u2019ve introduced, let\u2019s look again at the example in which 26% of the population is Black and 8 Black people are selected to be on a jury panel of 100 people. The null hypothesis H0 is \u201cThe jury panel was chosen at random from the population\u201d. We can map the null hypothesis onto the general framework above as follows:  \u2022 The statistic of interest is T0, the number of Black people in a sample of n = 100 panel members  \u2022 The population distribution is a Bernoulli distribution with the sample space Black, Non-Black  in which p(Black) = 0.26.  \u2022 The sample size is n = 100  \u2022 The number of replications k = 10 000",
      "We follow the procedure described in the previous section to give the results shown in Figure 3. Coding this up will be an exercise for you in the Labs. We can see that none of the 10 000 simulations of the null hypothesis produced a jury with 8 members, suggesting that we should reject the null hypothesis in favour of an alternative one. This looks like a clear-cut case; in the topic on Hypothesis testing, we\u2019ll consider in more detail how to interpret the results when the data is less distinct from the simulations.",
      "Deriving the sampling distribution Note that in this example, we didn\u2019t have to go to the trouble of running a simulation experiment. We might have noticed that the total number of Black people will be distributed according to a binomial distribution with n = 100 and p = 0.26.",
      "6",
      "10203040Number of black people on panel05001000FrequencySimulation010203040Number of black people on panel0.000.05ProbabilityBinomial distribution\f3 Video: Distributions of small samples statistics from probabil-  ity distributions",
      "Example of sampling from probability distributions In the previous example, we\u2019ve sampled a total number of successes from a Bernoulli distribution. We\u2019ll now look at what happens when we sample the mean, standard deviation and median from the normal, uniform and exponential distributions by running the following simulations:  \u2022 Statistics of interest: mean X, standard deviation S and median \u02dcX  \u2022 Population distribution: Normal distribution with mean 0 and variance 1, Uniform distribution  on [0, 1], Exponential distribution p(x) = e\u2212x.  \u2022 Sample size n = 10  \u2022 Number of replications k = 10, 000",
      "Figure 4. There are a number of points to notice about this plot:",
      "Sample mean (\ufb01rst column), all distributions The distribution of the mean is narrower than the original distribution in every case. This is because some of the variability in the individual samples is averaged out. The standard deviation of this distribution is called the standard error of the mean.",
      "Sample mean of normal distribution The distribution looks to be normal \u2013 it turns out that this is  easy to prove.",
      "Sample mean of uniform distribution The distribution is symmetric and looks to be near-normal.",
      "Sample mean of exponential distribution The distribution is clearly skewed, but less so than the  original exponential distribution.",
      "Sample variance (second column) All these distributions are skewed, re\ufb02ecting the fact that it\u2019s very unlikely to get 10 samples that are all very close together, and therefore have low variance. It turns out that there is a theoretical distribution (the \u03c72 distribution) that describes the shape of sample variance from the normal distribution.",
      "Median (third column) The main point to draw from this column is that we can use the simulation method to produce a distribution for any statistic, regardless of how easy it would be to calculate a theoretical distribution for it.",
      "As we will see later, we could generate the sampling distribution of the mean and the variance analytically rather than by simulation. However, it is not always possible to compute sampling distributions of the desired statistics analytically, but we can always run statistical simulations.",
      "4 Video: The distribution of the sample mean of large samples",
      "The distribution of the sample mean A particularly common statistic of interest is the sample mean. It therefore makes sense to understand how the distribution of the sample mean depends on the distribution from which we sample and the number of samples we take.",
      "7  \fFigure 4: Sampling distribution generated by 10,000 simulations of the mean x, variance s2 and median \u02dcx of 10 samples drawn from a normal distribution (top row), uniform distribution (middle row) and exponential distribution (bottom row).",
      "8",
      "101x0250500Frequency0.02.5s20500FrequencyNormal101x0250500Frequency0.250.500.75x0250500Frequency0.050.100.15s20200400FrequencyUniform0.250.500.75x0200400Frequency12x0250500Frequency010s2010002000FrequencyExponential02x0250500Frequency\fFigure 5: Distributions of means from samples of size n = 1000 (top row) and n = 10000 (bottom row) drawn from the normal, uniform and exponential distributions shown in Figure 2. The blue histograms show the histograms obtained from k = 2000 simulations. The orange curves are normal distributions with mean equal to the mean of the original distribution and variance \u03c3X equal to \u03c32\/n, where \u03c32 is the variance of the original distribution.",
      "9",
      "0.10.00.1x010Relative frequencyNormal n=10000.450.500.55x02040Uniform n=10000.91.01.1x0510Exponential n=10000.10.00.1x02040Relative frequencyNormal n=100000.450.500.55x0100Uniform n=100000.91.01.1x02040Exponential n=10000\fWe\u2019ve already seen in Figure 4 that the sampling distribution of the mean of 10 items from a normal distribution is itself a normal distribution, though with smaller variance. However, the sample mean distributions for an exponential distribution in our simulation, was not normal. We can repeat the simulation experiments for the three distributions, but with larger sample sizes of n = 1000 and n = 10000 (Figure 5). What we see is remarkable: the distributions of the sample means are all normal, regardless of whether they came from a normal, uniform or exponential distribution. Perhaps less remarkably, we also see that as the sample size gets larger the distributions get narrower.",
      "These simulations and observations give us the intuition for two very important statistical laws that apply to many non-normal distributions, as well as normal ones:  \u2022 The Central Limit Theorem  \u2022 The Law of Large Numbers",
      "Central Limit Theorem Here is an informal statement of the Central Limit Theorem (CLT):",
      "The distribution of the mean [or sum] of a random sample drawn from any distribution will converge on a normal distribution. In the case of the sample mean, its expected value is the same as the mean of the population distribution, and its expected variance is a factor of n lower than the population variance. In the case of the sample sum, its expected value is the same as the product of the sample size n and the expected value of the distribution, and its expected variance is n times the variance of the population distribution.  \u221a  n.  = \u03c3\/",
      "We denote the expected variance of the mean \u03c32 and we call the standard deviation of the mean \u03c3X, or X the standard error in the mean, often abbreviated as SEM. It\u2019s important to note that the SEM is not the same as the standard deviation of the original distribution. According to the statement above, an estimate of the SEM is \u02c6\u03c3X We can verify that this statement holds in the case of sampling a mean in Figure 5 by computing the means and SEM from the simulations and comparing with the expected values of \u00b5 (population mean) and \u03c3X The Swain versus Alabama jury selection example demonstrates the CLT applied to a total T0 = (cid:80)n i=1 Xi, where Xi = 1 indicates a Black member of the population was selected, and Xi = 0 indicates non-Black. The distribution is a Bernoulli distribution with population mean \u00b5 = p = 0.26, the probability of picking a Black person. We can see from Figure 3 that the mean of the total is n\u00b5 = 100 \u00d7 0.26 = 26, \u2248 n\u03c32 = 19.24, as expected for a Bernoulli distribution, giving and the variance is approximately \u03c32 T0 a standard deviation of 4.38. Furthermore, the distribution is approximately normal.  = \u03c3\/  n.  \u221a",
      "The law of large numbers Here is an informal statement of the law of large numbers:",
      "In the limit of in\ufb01nite n, the expected value of the sample mean X tends to the population mean \u00b5 and the variance of the sample mean X tends to 0.",
      "Note that sometimes the law of large numbers is referred to as the \u201claw of averages\u201d. This can lead to confusion. The law of averages is sometimes called the \u201cGambler\u2019s fallacy\u201d, i.e. the idea that after a run of bad luck, the chance of good luck increases. If the events that are being gambled on are independent of each other (e.g. successive tosses of the same coin), the probability of a head will be the same regardless of how many tails have preceded it.",
      "10  \fIn the second row of Figure 5 we can see that the distribution for n = 10000 is narrower than the distribution for n = 1000, and that the sample means converge on the population means. The law of large numbers says that we could, in principle, continue this process by choosing an n as large as we would like to make the variance as small as desired.",
      "Formal statement of the central limit theorem (Modern Mathematical Statistics with Applica- tions 6.2) Let X1, . . . , Xn be a random sample from a distribution with mean \u00b5 and variance \u03c32. Then, in the limit n \u2192 \u221e the standardised mean ((X \u2212 \u00b5)\/(\u03c3\/ n\u03c3)) have a normal distribution. That is  n)) and standardised total ((T0 \u2212 n\u00b5)\/(  \u221a  \u221a  \uf8eb \uf8ec\uf8ec\uf8ec\uf8ec\uf8ed",
      "X \u2212 \u00b5 \u221a n \u03c3\/  \uf8f6 \uf8f7\uf8f7\uf8f7\uf8f7\uf8f8  \u2264 z  lim n\u2192\u221e",
      "P  = P(Z \u2264 z) = \u03a6(z)  and",
      "P  \uf8eb \uf8ec\uf8ec\uf8ec\uf8ec\uf8ed  lim n\u2192\u221e",
      "T0 \u2212 n\u00b5 \u221a n\u03c3  \uf8f6 \uf8f7\uf8f7\uf8f7\uf8f7\uf8f8 \u2264 z where \u03a6(z) is the cumulative distribution function (cdf) of a normal distribution with mean 0 and s.d. 1. = \u00b5 Thus, when n is su\ufb03ciently large, X has an approximately normal distribution with mean \u00b5X = n\u00b5 and and variance \u03c32 X = n\u03c32. We can also say that the standardised versions of X and T0 are asymptotically variance \u03c32 T0 normal.  = \u03c32\/n and the distribution of T0 is approximately normal with mean \u00b5T0  = P(Z \u2264 z) = \u03a6(z)",
      "Formal statement of the (weak) law of large numbers Applications 6.2) Let X1, . . . , Xn be a random sample from a distribution with mean \u00b5 and variance \u03c32. As the number of observations n increases, the expected value of the sample mean remains E[X] = \u00b5, but the expected variance V[X] = E[(X \u2212 \u00b5)2] \u2192 0. We say that \u201cX converges in mean square to \u00b5\u201d. More formally, the probability that the di\ufb00erence between the sample mean and population mean is greater than an arbitrary value \u03b5 is  (Modern Mathematical Statistics with",
      "P(|X \u2212 \u00b5| \u2265 \u03b5) \u2264  \u03c32 n\u03b52  for any value \u03b5. Thus, as n \u2192 \u221e, the probability approaches 0, regardless of the value of \u03b5.",
      "A proof of this statement relies on Chebyshev\u2019s inequality, and can be found in Modern Mathematical Statistics with Applications 6.2.",
      "Note that this is the statement of the weak law of large numbers. There is also a strong law, which has somewhat more stringent requirements on convergence. All distributions that obey the strong law also obey the weak law, but some distributions only obey the weak law and some obey neither law. A discussion of this topic is beyond the scope of this course; the distributions that do not obey the distribution tend to be \u201cweird\u201d, e.g. having in\ufb01nite variance.",
      "Appendix",
      "Frequentist versus Bayesian statistics You may have heard of the di\ufb00erence between Frequentist and Bayesian statistics. The two systems have di\ufb00erent philosophical bases, but, in simpler cases, often end with similar results. Roughly speaking, the di\ufb00erences between the two are:",
      "11  \fFrequentist The population is a fundamental concept. There is just one possible value of the popula- tion mean and variance, i.e. the one that exists in the population. In estimation, we are trying to estimate these quantities, and in hypothesis testing, we are trying to compare our sample with this population.",
      "Bayesian A fundamental concept is the model of the likelihood of the data given parameters (such as the mean). The parameters themselves are uncertain. Conceptually, the population itself is generated from the model, so a number of combinations of parameters and luck may have generated the particular value of (say) the mean observed in a population. Before we have seen any data, we have an initial idea about the distribution of the parameters (the prior). The inference process involves using the data to update this prior distribution to give a distribution of the parameters given the data.",
      "For around a century, there has been controversy about which approach is best. Broadly speaking, we will be using Frequentist approaches in this course. At the level we are working at here, it will give very similar results to Bayesian approaches. The important thing is to understand the meaning and interpretation of our inference.",
      "References",
      "Gelman, A., Carlin, J. B. et al. (2004). Bayesian Data Analysis. Chapman & Hall\/CRC, second ed.",
      "Kohavi, R., Henne, R. M. et al. (2007). \u2018Practical guide to controlled experiments on the web: Listen to your customers not to the HiPPO\u2019. In P. Berkhin, R. Caruana, X. Wu and S. Ga\ufb00ney, eds., KDD-2007 Proceedings of the thirteenth ACM SIGKDD international conference on knowledge discovery and data mining, pp. 959\u2013967. Association of Computing Machinery, New York, USA",
      "12"
    ]
  },
  "3": {
    "title": "FDS-S1-11-2-confidence-intervals",
    "content": [
      "Inf2 \u2013 Foundations of Data Science 2021 Topic: Con\ufb01dence intervals",
      "David C. Sterratt",
      "17th May 2022",
      "Recommended reading:  \u2022 Computational and Inferential Thinking, Chapter 13  \u2022 Modern Mathematical Statistics with Applications, Sections 8.1\u20138.3 and 8.5",
      "1 Video: Principle of con\ufb01dence intervals",
      "Illustration: con\ufb01dence intervals for the mean From the Central Limit Theorem we know that for large samples, the distribution of the mean is normal, and that the estimated standard error of the mean should be close to the standard error in the mean. We can then ask \u201cif we looked at an interval around our estimate for the mean, how often would the true value be contained in that interval\u201d?",
      "Figure 1 gives an illustrated answer to this question. Each blue horizontal line corresponds to one sample of size n from a population, and shows a range of estimates for the population mean based on that sample \u2013 in other words a con\ufb01dence interval. We can see that the true value of the mean (black vertical line) is contained in most of the intervals, but not all of them.",
      "Size of con\ufb01dence interval We have chosen the length of the intervals to ensure that, if we carried on estimating the mean and the interval, about 95% of intervals would contain the true mean. To determine this length, we use the z critical values of the normal distribution (Figure 2). We de\ufb01ne the z critical value z\u03b1 as the value of z in a normal distribution which has the area \u03b1 under the curve to its right. If we want the intervals to contain the true mean 95% of the time, we need to make sure that the mean is within the central 95% of the distribution. This implies that we need 2.5% of the area under the curve to the right of the upper bound, so we look up z0.025 in a statistical table or a function in a stats package and \ufb01nd that z0.025 = 1.96 \u2013 we will show how to do this later. The z critical value of 1.96",
      "1  \fFigure 1: Principle of con\ufb01dence intervals. We repeat a simulation using a sample size of n = 100 to estimate the sample mean of a normal distribution with mean 0 and standard deviation 1. The black vertical line indicates the true mean, the blue dots indicate the sample means, and the blue horizontal lines indicate the 95% con\ufb01dence intervals obtained in each of the 20 repetitions. It can be seen that 19 of the con\ufb01dence intervals do contain the population mean, but one of them does not.",
      "Figure 2: Con\ufb01dence intervals of a normal distribution. The intervals containing various amounts of probability mass under a normal distribution are shown. The 95% con\ufb01dence interval (blue) is [\u22121.96, 1.96] and has 2.5% of the probability mass in each tail. The 80% con\ufb01dence interval is [\u22121.28, 1.28]. The amount of probability mass contained in one standard deviation is 68%. In general for a con\ufb01dence interval of 100(1 \u2212 \u03b1)%, the upper and lower boundaries are determined by the z critical value z\u03b1\/2. E.g. with the 95% con\ufb01dence interval \u03b1 = 0.05 and there is 2.5% of the area of the curve above the upper boundary of the con\ufb01dence interval.",
      "2",
      "0.40.20.00.20.4 and CIs for 05101520Repetition\fFigure 3: Concept of the z critical value. Top: z\u03b1 is the value of z such in a normal distribution such that the area under the curve to the right of the z\u03b1 (green) is equal to \u03b1. i.e. \u03b1 = (cid:82) \u221e p(z)dz. Bottom: z\u03b1 the blue curve shows the cumulative distribution function \u03a6(z) = (cid:82) z \u2212\u221e p(z)dz. The orange curve shows the \u201csurvival function\u201d sf(z) = 1 \u2212 \u03a6(z). The survival function of z is exactly the area to the right of z under the pdf. Therefore we want to look up the inverse survival function to determine z\u03b1 from \u03b1, as indicated by the green lines.  tells us that the length of the lines on the side of each estimate of the mean should all be 1.96 times the standard error of the mean (SEM).",
      "We may want to be more or less certain of whether the mean is contained in a con\ufb01dence interval. In this case we can look up the z critical value for our chosen level of con\ufb01dence. We can also decide to express the con\ufb01dence interval in terms of the multiples of the SEM. For example con\ufb01dence intervals of plus or minus one SEM correspond to a 68% con\ufb01dence interval.",
      "Reminder It is worth remembering that these simulations are arti\ufb01cial in the sense that we can repeat many samples. In real life we only get one sample, which does or does not contain the true value \u2013 but we don\u2019t know.",
      "Looking up a z critical value (added after 2021\/22 lectures) To look up a z critical value, you can use the python scipy package. For example to \ufb01nd z0.2 you would use:  from scipy .stats import norm alpha = 0.2 print (norm.isf(alpha ))",
      "The function name isf stands for inverse survival function. As illustrated in Figure 3, it\u2019s the inverse of one minus the cumulative distribution function (cdf).",
      "3",
      "432101234z0.00.20.4p(z)432101234z0.00.51.0=0.2z0.2=0.84(z)1(z)\f2 Video: De\ufb01nition of con\ufb01dence intervals",
      "De\ufb01nition of con\ufb01dence intervals We de\ufb01ne a con\ufb01dence interval as an interval ( \u02c6\u03d1\u2212a \u02c6\u03c3 \u02c6\u03d1, \u02c6\u03d1+b \u02c6\u03c3 \u02c6\u03d1) that has a speci\ufb01ed chance 1 \u2212 \u03b1 of containing the parameter, and where the positive numbers a and b de\ufb01ning the lower and upper bounds of the interval depend on \u03b1. The smaller \u03b1 is, the larger the values of a and b can be for the statement to hold. A common value for \u03b1 is 0.05 (i.e. 5%), which gives a 95% con\ufb01dence interval. However, we could set \u03b1 = 0.2, which would give a narrower 80% con\ufb01dence interval. Often a and b are equal, but we have given them distinct symbols for full generality.",
      "We can express the de\ufb01nition in terms of a probability statement as follows:  (cid:16) \u02c6\u03d1 \u2212 a \u02c6\u03c3 \u02c6\u03d1 < \u03d1 < \u02c6\u03d1 + b \u02c6\u03c3 \u02c6\u03d1  (cid:17) = 1 \u2212 \u03b1",
      "P  (1)",
      "In this probability statement, the upper and lower bounds of the interval are random variables, since they are based on the estimators and the estimated standard error, which are themselves random variables derived from the sample.",
      "Expression in terms of random variable in \ufb01xed interval We can rearrange the de\ufb01nition of the con\ufb01dence interval in terms of a standardised variable ( \u02c6\u03d1 \u2212 \u03d1)\/ \u02c6\u03c3 \u02c6\u03d1:  (cid:32) \u2212b <",
      "P  (cid:33)  < a  \u02c6\u03d1 \u2212 \u03d1 \u02c6\u03c3 \u02c6\u03d1  = 1 \u2212 \u03b1  (2)",
      "Because this standardised variable is derived from the sample, it \ufb01ts our de\ufb01nition of a statistic. Furthermore, it is composed of two statistics, the estimator \u02c6\u03d1 and the estimated standard error \u02c6\u03c3 \u02c6\u03d1.",
      "3 Video: Method of estimating con\ufb01dence interval of the mean  of a large sample",
      "Methods of estimating con\ufb01dence intervals There are two main methods of estimating con\ufb01dence intervals:",
      "1. Under some assumptions about the distribution of the data Xi and the number of samples n we can derive the distribution of ( \u02c6\u03d1 \u2212 \u03d1)\/ \u02c6\u03c3 \u02c6\u03d1, which will then tell us the values of \u2212b and a at the 100\u03b1\/2th centile and the 100(1 \u2212 \u03b1\/2)th centiles.",
      "2. More generally we can use a type of statistical simulation called a bootstrap estimator to derive  the con\ufb01dence interval.",
      "We\u2019ll demonstrate the \ufb01rst approach by continuing with our simpli\ufb01ed example of a normal distribution with known parameters. In the following section we\u2019ll then cover the bootstrap estimator.",
      "Example: con\ufb01dence interval for the mean of a normal distribution with known variance In the example of sampling from a normal distribution introduced in the last video, we know the population n. Because the population variance \u03c3, and by de\ufb01nition, the standard estimate of the mean is \u02c6\u03c3 \u02c6\u03d1 variance \u03c3 is known, it\u2019s not a random variable, and therefore the SEM \u02c6\u03c3 \u02c6\u03d1 isn\u2019t a random variable either. The standardised variable in Equation 2 is therefore  = \u03c3\/  \u221a  \u02c6\u03d1 \u2212 \u03d1 \u02c6\u03c3 \u02c6\u03d1  = X \u2212 \u00b5 \u221a n \u03c3\/",
      "4  (3)  \fFigure 4: Distribution of time from making a reservation to the reservation time (\u201cpreparation time\u201d ) in restaurants using the \u201cair\u201d booking system in Japan in the period January 2016\u2013April 2017.  and only contains one random variable, X. This makes it quite easy to deal with, since we know that this distribution is a standard normal distribution, so we can de\ufb01ne a 95% con\ufb01dence interval by setting a and b to be values at which the cumulative distribution function (cdf) is equal to 2.5%(= \u03b1\/2) and 97.5%(= 1 \u2212 \u03b1\/2). In this case the values a = b = 1.96 satisfy these conditions. Generally we set a and b symmetrically, so that there is equal weight in the \u201ctails\u201d of the distribution (Figure 2).",
      "Con\ufb01dence intervals for the mean of a large sample The central limit theorem states that the distribution of the sample mean of a \u201clarge\u201d sample from any distribution should be normal. How large the sample needs to be depends on the distribution, but Figure 1 demonstrates that sample means of n = 100 samples from an exponential distribution already appear to fairly normally distributed with n. This the SEM as predicted to be the standard deviation of the exponential distribution divided by means that we can use the procedure above to \ufb01nd con\ufb01dence intervals.  \u221a",
      "Con\ufb01dence intervals for the mean of an empirical distribution Up until now, we have considering estimating parameters from theoretical probability distributions, such as the normal distribution or the exponential distribution. We\u2019ll now consider how we can estimate the parameters of an empirical distribution, i.e. real-world data, from a sample of that distribution.",
      "As an example, we will take the population of times between making a reservation and the time of the reservation itself in Japanese restaurants using the \u201cair\u201d booking system. The full population contains 92378 times (Figure 4, left) and we\u2019ve created a random sample of 1000 of these times (Figure 4, right). In real life, if we had the full set of data, there would not be any point in creating this random sample of times, but we do so here to demonstrate how well we can estimate con\ufb01dence intervals. From now on imagine that the sample of 1000 times is all that we have available to us. It\u2019s important to notice that the distribution of the sample resembles the population distribution, even though it is rougher.",
      "Table 1 shows the summary statistics for the population and the sample. We can see that the estimates for the mean, standard deviation and centiles from the sample are all similar to the true population values. From the table we can see that the population mean is \u00b5 = 8.30 days and the sample mean is x = 8.06 days. The sample mean would be di\ufb00erent if we\u2019d happened to have taken a random di\ufb00erent",
      "5",
      "020406080100Preparation time (days)050001000015000200002500030000NumberPopulation020406080100Preparation time (days)0100200300400500Sample n = 1000\fTable 1: Summary statistics of population and sample of preparation times, generated by the pandas describe function.",
      "Population",
      "Sample",
      "92378.00 8.30 25.65 0.00 0.21 2.08 7.88 393.12",
      "1000.00 8.06 27.72 0.00 0.17 1.96 6.92 364.96  count mean std min 25% 50% 75% max  sample. From the summary statistics from the sample, we have x = 8.06 days and the standard deviation s = 27.72 days. Our estimator for the mean is \u02c6\u03d1 = x = 8.06 days. Our estimator for the standard error 1000 = 0.88 days. The 95% con\ufb01dence interval for the mean in n = 27.72\/ in the mean is \u02c6\u03c3 \u02c6\u03d1 days is therefore ( \u02c6\u03d1 \u2212 1.96 \u02c6\u03c3 \u02c6\u03d1, \u02c6\u03d1 + 1.96 \u02c6\u03c3 \u02c6\u03d1) = (6.34, 9.78).  = s\/  \u221a  \u221a",
      "Reporting con\ufb01dence intervals When reading scienti\ufb01c papers, there are various ways of reporting con\ufb01dence intervals:  \u2022 M=8.06, CI=6.34\u20139.78. Here \u201cM\u201d stands for mean and \u201cCI\u201d stands for con\ufb01dence interval.  \u2022 8.06 \u00b1 1.72 (95% con\ufb01dence interval)  \u2022 8.06 \u00b1 0.88 (\u00b1 1 SEM). This is a 68% con\ufb01dence interval, though the con\ufb01dence interval isn\u2019t  speci\ufb01ed in terms of area under the curve.  \u2022 8.06 \u00b1 1.76 (\u00b1 2 SEM).",
      "4 Video: Bootstrap estimation of con\ufb01dence intervals",
      "Principle of a bootstrap estimator We want to estimate the standard error in an estimator. In the topic on sampling, we have already seen what happens when we sample a mean repeatedly from a theoretical distribution, and that this can give us a measure of the standard error of the estimator.",
      "The name \u201cbootstrap estimator\u201d arises because it appears to do something physically impossible, such as \u201cpulling ourselves up by our own bootstraps\u201d. (Equivalently we could pull ourselves up by our pigtail, Figure 5).",
      "In a bootstrap estimator we treat the sample that we have available as a population, and resample from it to give the sampling distribution of the estimator. From the sampling distribution we can compute the standard error of the estimator. It feels as though we shouldn\u2019t be able to treat the sample as a population, but it works because if we have a large enough sample, the distribution of the sample will resemble the population itself.",
      "6  \fFigure 5: Bootstrapping: Baron M\u00a8unchhausen pulls himself and his horse out of a swamp by his pigtail. Public domain image from Wikipedia\u2019s article on bootstrapping.",
      "Bootstrap procedure for \ufb01nding a con\ufb01dence interval for the mean We will start with a large sample n from the data, which has a mean x. By large, we mean large enough that the sample resembles the population distribution. Of course, this is not possible to know exactly, so the larger the better. We decide to take B bootstrap samples. Common numbers are 1000 or 5000, or 10000. More samples are generally better, but bootstrapping can be computationally expensive, and fewer samples can also give reasonable results.",
      "Here is the procedure:  \u2022 For j in 1, . . . , B  \u2013 Take sample x\u2217 of size n from the sample with replacement \u2013 Compute the sample mean of the new sample x\u2217 j  \u2022 To compute the bootstrap con\ufb01dence interval, we \ufb01nd the centiles of the distribution at 100\u03b1\/2 j in order from lowest to j at k = B\u2212\u03b1(B+1)\/2  and 100(1 \u2212 \u03b1\/2). We can do this by arranging the sample means x\u2217 highest, and pick x\u2217 to be the upper end of the CI.  j at k = \u03b1(B+1)\/2 to be the lower end of the CI and pick x\u2217  \u2022 We can also compute the bootstrap estimator of the variance of the mean:  s2 boot  =  (cid:80)B  j=1(x\u2217  j \u2212 x)2",
      "B \u2212 1",
      "The advantages of the bootstrap procedure are that we can use it for any estimator, e.g. the median, and that we do not need to make any assumptions about the distribution of the estimator.",
      "7  \fFigure 6: Demonstration of bootstrap mean applied to restaurant reservation time data (Figure 4). The top row shows the distributions obtained from the \ufb01rst 3 of 10000 bootstrap samples. Although the distributions are similar to each other, they are not exactly the same, and the sample mean of each is di\ufb00erent. The bottom \ufb01gure is the distribution of all 10000 of these bootstrap sample means. The mean of the original sample is shown, as is the 95% and 80% con\ufb01dence intervals.",
      "8",
      "050100x*0200400x*1 = 7.19j = 1050100x*0200400x*2 = 7.45j = 2050100x*0200400x*3 = 7.20j = 36789101112X* (days)0100200300Mean = 8.0695% CI = [6.46, 9.90]80% CI = [6.97, 9.22]Distribution of 10000 boostrap means\fExample of bootstrap estimator applied to mean We\u2019ll now apply the bootstrap estimator to give us a con\ufb01dence interval for the mean (Figure 6). For each of our 10,000 bootstrap samples, we\u2019ll resample 1000 samples with replacement from our sample of 1000. Each of these samples will be a distribution (top row of Figure 6), from which we can compute the 10,000 bootstrap means. Then we\u2019ll plot the distribution of the bootstrap means (bottom row of Figure 6) and \ufb01nd the 95% and 80% con\ufb01dence intervals. In this case we can see both the 95% and 80% con\ufb01dence intervals contain the population mean (8.30, Table 1). However, if we replicate the experiment with a di\ufb00erent initial random sample of 1000, in around 5% of cases we should expect that the 95% con\ufb01dence interval does not contain the mean. We\u2019ll leave this as a lab exercise for you to implement, though you will \ufb01nd that you get di\ufb00erent answers for the con\ufb01dence intervals, depending on the state of the random number generator.",
      "Comparison of bootstrap con\ufb01dence intervals with normal approximation The 95% con\ufb01dence interval obtained via the bootstrap procedure is (6.46, 9.90) days, which is very similar to the con\ufb01dence interval obtained by the normal approximation, (6.34, 9.78) days. The bootstrap interval is slightly shifted to the right, suggesting that the normal approximation is quite accurate at a sample size of n = 1000.",
      "General formulation of bootstrap estimator A great advantage of the bootstrap is that we can easily apply it to statistics other than the mean. Here is the general procedure for estimating the con\ufb01dence interval of a generic estimator \u02c6\u03d1:  \u2022 For j in 1 . . . B  \u2013 Take sample x\u2217 of size n from the sample with replacement \u2013 Compute the sample statistic of the new sample \u02c6\u03d1\u2217 j  \u2022 Then compute the bootstrap estimator of the variance of the statistic:  s2 boot  =  (cid:80)B  j=1( \u02c6\u03d1\u2217  j \u2212 \u02c6\u03d1)2",
      "B \u2212 1  \u2022 To compute the bootstrap con\ufb01dence interval, we \ufb01nd the centiles of the distribution at 100\u03b1\/2  and 100(1 \u2212 \u03b1\/2).",
      "This procedure works well for measures of centrality such as the median, and for the variance. It doesn\u2019t work so well for statistics of extremes of the distribution, such as the maximum or minimum.",
      "5 Video: Interpretation of con\ufb01dence intervals",
      "Interpretation of con\ufb01dence intervals Although we have only computed con\ufb01dence intervals in a simple arti\ufb01cial example, we are already at a stage where we can consider how to interpret con\ufb01dence intervals. From Equation 1 we can see that con\ufb01dence intervals are a random interval \u2013 whenever we take a new sample, we will end up with a new interval, as illustrated in Figure 1. The interpretation (according to the frequentist interpretation of statistics) is that if we performed a long run of experiments (i.e. repeatedly took samples) the parameter (the mean in this case) would be in around 95% of the con\ufb01dence intervals.",
      "9  \fHow big should a con\ufb01dence interval be? Should we choose the 95% con\ufb01dence interval or the 80% con\ufb01dence interval? The answer to this question depends on the problem. For example, suppose we have a machine that makes tens of thousands of ball bearings for aircraft jet engines every day. Each ball bearing needs to have a diameter of 2 \u00b1 0.0001mm for the engine to work safely. We measure the diameter of a sample of the ball bearings every day. Because this is a safety-critical application, we need to have high con\ufb01dence (say 99.999%) that the ball bearings are in the range 2 \u00b1 0.0001mm. This might require a large sample size, but it\u2019s worthwhile because the consequences of getting it wrong could be catastrophic.",
      "On the other hand, suppose we are estimating the number of red squirrels in a population so that we know how much red-squirrel friendly food to put out for them over winter. We might want to leave out a bit more than we expect they need, we\u2019re happy to accept a 10% chance that the true number of squirrels might be greater than the upper end of a con\ufb01dence interval, so we compute the 80% con\ufb01dence interval, and put out enough food for the number of squirrels at the upper end of the interval. There\u2019s a 10% chance that we might not be providing for enough squirrels, but it\u2019s not as catastrophic as in the aircraft situation (depending on how much you value red squirrels compared to humans).",
      "Upper and lower con\ufb01dence bounds In this case, we\u2019re not worried about our estimate being too low, so we only need to compute the upper con\ufb01dence bound \u2013 we would quote a mean number of squirrels and an upper limit.",
      "Aside: Capture-recapture Suppose we want to estimate the number of squirrels N in a population. We can do this with a clever method called capture-recapture:",
      "1. Capture n of the squirrels, tag them so that they can be identi\ufb01ed if caught again, then release  them.",
      "2. Wait for the squirrels to move around.",
      "3. Recapture K of the squirrels and record the number k of these recaptured squirrels that have tags.",
      "4. The estimator of the number of squirrels in the population is  \u02c6N = nK k",
      "This should work if the capturing and recapturing processes are random. If this is the case, the expected proportion of tagged squirrels in the whole population n\/N is equal to the proportion in the recaptured sample k\/K, hence the estimator. It\u2019s possible to derive theoretical con\ufb01dence intervals for this estimator.",
      "6 Video: Con\ufb01dence intervals on the mean for small samples",
      "Small samples We\u2019ll now consider the distribution of the mean based on a sample of a \u201csmall\u201d number (usually n < 40) of data that appears to be distributed normally and whose variance we are not given \u2013 we can only estimate it from the data.",
      "For example, suppose we want to estimate the mean weight of a population of female squirrels from a sample of n = 32 squirrels (Wauters and Dhondt, 1989). The sample mean is x = 341.0g and the estimated standard error in the mean is \u02c6\u03c3X  = 3.9g.",
      "10  \fFigure 7: The t-distribution for 3 degrees of freedom and 10 degrees of freedom, with normal distribution for comparison. 2.5% t critical values and z critical values are shown.",
      "We can imagine that if we had taken a di\ufb00erent sample of n = 32 squirrels, we would have found both a di\ufb00erent sample mean and a di\ufb00erent estimate for the standard error in the mean. Thus, the standardised statistic (X \u2212 \u00b5)\/ \u02c6\u03c3X itself contains two statistics, X and \u02c6\u03c3X, which are, in general, random variables derived from the sample. As we are estimating the standard deviation, rather than knowing it, the normal approximation to the distribution of the mean begins to break down.",
      "The t-distribution We could use the bootstrap estimator to estimate con\ufb01dence intervals. However, in this special case, there is another option. There\u2019s a theorem that states that when X is a random sample of size n from a normal distribution with mean \u00b5, the random variable",
      "T = X \u2212 \u00b5 \u02c6\u03c3X  is distributed as a t-distribution with n \u2212 1 degrees of freedom, where the t-distribution with \u03bd degrees of freedom has the probability density function depicted in Figure 7, which is given by the equation:  p\u03bd(t) = 1 \u221a \u03c0\u03bd  \u0393((\u03bd + 1)\/2) \u0393(\u03bd\/2)",
      "1 (1 + t2\/\u03bd)(\u03bd+1)\/2  where \u0393(x) is a gamma function. We will not prove this theorem here; in Modern Mathematical Statistics with Applications Section 6.4 there is the sketch of a proof.",
      "The t-distribution is very similar in shape to the normal distribution: it is bell-shaped, symmetrical, and centred on 0. However, for small numbers of degrees of freedom, has longer tails. This means that the tails contain more of the weight of the distribution. We de\ufb01ne the t critical value t\u03b1,\u03bd as the value of t in a t-distribution with \u03bd degrees of freedom which has the area \u03b1 under the curve to its right.",
      "For small degrees of freedom, the t critical values are considerably bigger than the z critical values of the normal distribution (Figure 7). As the number of degrees of freedom increases, the t-distribution approaches a normal distribution. The distribution with 40 degrees of freedom (not shown in the \ufb01gure) looks very similar to a normal distribution.",
      "11",
      "432101234t0.10.00.10.20.30.4pz0.975t0.975,10t0.975,3z0.025t0.025,10t0.025,3Normalt, 10 d.ft, 3 d.f.\fTable 2: Abbreviated table of critical values for t and z distributions.",
      "0.100",
      "0.050",
      "0.025",
      "0.010",
      "0.005",
      "0.001  \u03b1 \u03bd",
      "3.078 1 1.886 2 1.638 3 1.533 4 1.476 5 1.440 6 1.415 7 1.397 8 1.383 9 1.372 10 1.325 20 1.310 30 40 1.303 \u221e 1.282",
      "6.314 2.920 2.353 2.132 2.015 1.943 1.895 1.860 1.833 1.812 1.725 1.697 1.684 1.645",
      "12.706 4.303 3.182 2.776 2.571 2.447 2.365 2.306 2.262 2.228 2.086 2.042 2.021 1.960",
      "31.821 63.657 9.925 6.965 5.841 4.541 4.604 3.747 4.032 3.365 3.707 3.143 3.499 2.998 3.355 2.896 3.250 2.821 3.169 2.764 2.845 2.528 2.750 2.457 2.704 2.423 2.576 2.326",
      "318.309 22.327 10.215 7.173 5.893 5.208 4.785 4.501 4.297 4.144 3.552 3.385 3.307 3.090",
      "Looking up a t critical value (added after 2021\/22 lectures) To look up a t critical value, you can use the python scipy package. For example to \ufb01nd t0.025,10 you would use: from scipy . stats import t alpha = 0.025 nu = 10 t_cv = t(nu ). isf( alpha) print (t_cv)",
      "You can also look up t critical values and z critical values in statistical tables, such as the ones in the appendices of Modern Mathematical Statistics with Applications. Table 2 shows an abbreviated example of such a table. Each row contains t critical values for degree various levels of \u03b1. The \ufb01nal row, with in\ufb01nite number of degrees of freedom, is the z critical values for these values of \u03b1. The full tables include values for more degrees of freedom.",
      "Using the t-distribution to derive a con\ufb01dence interval The 100(1 \u2212 \u03b1) percent con\ufb01dence interval around a mean x of a sample of n values with estimated SEM \u02c6\u03c3X derived using a t-distribution is: (x \u2212 t\u03b1\/2,n\u22121 \u02c6\u03c3X , x + t\u03b1\/2,n\u22121 \u02c6\u03c3X)  (4)",
      "Note that we have used the t critical value t\u03b1\/2,\u03bd. Here the number of degrees of freedom is one less than the sample size (\u03bd = n \u2212 1). Also, we have divided \u03b1 by 2 because we are wanting upper and lower bounds to the con\ufb01dence interval. It might be that we only need an upper bound, as we considered when we were estimating squirrel numbers earlier. In this case we would just quote x + t\u03b1,n\u22121 \u02c6\u03c3X. This is still a 100(1 \u2212 \u03b1) con\ufb01dence interval, since the interval from \u2212\u221e to the upper bound contains 100(1 \u2212 \u03b1) of the area under the t-distribution.",
      "To continue the squirrel example, suppose we want to \ufb01nd a 95% con\ufb01dence interval for the weight. The 95% con\ufb01dence interval implies \u03b1 = 0.05 and \u03bd = n \u2212 1 = 31. We would then look up the t0.025,31 = 2.040 and substitute it into Equation 4 along with the sample mean and estimated SEM. and then use this to generate the con\ufb01dence interval, which we could quote as \u02c6\u00b5 = 341.0 \u00b1 8.0g",
      "12  \f(95% con\ufb01dence interval, n = 32). This is a bit wider than the interval we would obtain using the corresponding critical value of a normal distribution z0.025 = 1.96.",
      "References",
      "Wauters, L. A. and Dhondt, A. A. (1989). \u2018Variation in length and body weight of the red squirrel  (Sciurus vulgaris) in two di\ufb00erent habitats\u2019. Journal of Zoology 217:93\u2013106",
      "13"
    ]
  }
}