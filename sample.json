{
    "1": "Remainder of semester 1 Hello everyone! I will take over the teaching for the remainder of semester 1, and also a large part of semester 2. Plan for (rest of) semester 1: 11. The Heap data structure 12. BuildHeap and HeapSort: running-time 13. QuickSort 14. Graphs I: graph data structures, Breadth-first search 15. Graphs II: DFS, connected components,TopSort",
    "2": "The Heap Definition A (max) heap is a \u201cnearly complete\u201d binary tree structure storing items in nodes, where every node is greater than or equal to each of its child nodes. (cid:73) The rule for parent/child key values is weaker over the tree as a whole than what we have for red-black trees, 2-3-4 trees or AVL trees (in those cases the tree encodes a total-ordering on the keys in the nodes). (cid:73) But . . . the topology of a heap is more restricted than for those other tree structures - we have a binary tree with leaves appearing at depth h and depth h \u2212 1, and all depth-h leaves grouped together to the left. (cid:73) The heap does not (readily) carry total-order information, but is ideally set-up to efficiently answer \u201cmax\u201d questions (suitable for priority queues). (cid:73) Neat structure of the topology means we can store the heap in an array.",
    "3": "Example heap Direct mapping: k-th element of heap stored in index k \u2212 1. Can use (2i \u2212 1) + j \u2212 1 for index of jth element on level i. (depends on \u201cAlmost-complete\u201d property).",
    "4": "Heaps: height and size A heap is an almost-complete binary tree: (cid:73) All leaves are either at depth h \u2212 1 or depth h (where h is height). (cid:73) The depth-h leaves all appear consecutively from left-to-right. . . . A heap of height h has between 2h and 2h+1 \u2212 1 nodes. 2h \u2264 n \u2264 2h+1 \u2212 1. Hence taking lg across this inequality, we see h \u2264 lg(n) < h + 1. This will put h in the range [lg(n) \u2212 1, lg(n)], ie \u0398(lg(n)). Lots of our Heap algorithms have worst-case running-time directly related to the height of the Heap.",
    "5": "Main operations on a Heap We imagine that the heap is stored in the array A. Heap-Maximum Returns the max element of a Heap - \u0398(1) time. Max-Heapify Runs in O(lg(n)) time and is used to maintain the (max) Heap property whenever some node/index i has violated the heap rule (but left subtree, right subtree are each legal Max Heaps). Heap-Extract-Max Can return (and delete) the maximum item of a Heap in O(lg(n)) time. Max-Heap-Insert Can insert a new item (and maintain the heap property) in O(lg(n)) time. Same for Heap-Increase-Key. Build-Max-Heap Special one called Build-Max-Heap will run in O(n) time to build a Heap from scratch from an unordered input array.",
    "6": "Max-Heapify and the other operations The Max-Heapify operation (called at i) is used to \u201cfix-up\u201d a Heap where the left-subtree Left(i) is a Heap, and so is the right-subtree Right(i) . . . but the value at i violates the Heap property. (cid:73) We will show that Max-Heapify can be implemented in time O(h) for the height h of the heap, which is O(lg(n)). (well, specifically, the height of the Heap rooted at i) (cid:73) We can then implement Heap-Extract-Max via the trick of just . . . (cid:73) Swapping A[0] (the max element) with A[A.heap size \u2212 1] (the last (cid:73) Then calling Max-Heapify(0) on the Heap to \u201cfix\u201d the error at the item in the array, and decrementing A.heap size. root. (cid:73) Max-Heapify is also key to the implementation of Build-Max-Heap.",
    "7": "Heap-Extract-Max The main work is not returning the max element (\u0398(1) time) but removing the max from the tree. We copy over the \u201clast node\u201d onto the root, then call Max-Heapify to fix things.",
    "8": "Max-Heapify We assume that the \u201cleft-heap\u201d Left(i) and the \u201cright-heap\u201d Left(i) are both accurate. Then Max-Heapify(i) will \u201cpatch-up\u201d the heap from i. Algorithm Max-Heapify(A, i) (cid:96)\u2190 Left(i) r \u2190 Right(i) largest\u2190 i largest\u2190 (cid:96) largest\u2190 r if largest (cid:54)= i 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. if (cid:96) < A.heap size and A[(cid:96)] > A[i] if r < A.heap size and A[r ] > A[largest] exchange A[i] with A[largest] Max-Heapify(A, largest)",
    "9": "Max-Heapify We are calling Max-Heapify from the root node. Max child of root is 48 on right, need to swap, and then recursively call Max-Heapify on 30 as the child (as in line 10. of the Algorithm).",
    "10": "Max-Heapify . . . Max child of 30 is 45 on left, need to swap, and then call heapify on 30 as the child.",
    "11": "Max-Heapify . . . Max child of 30 is 4, less than 30. ok. Finish.",
    "12": "Max-Heap-Insert Algorithm Max-Heap-Insert(A, k) 1. A.heap size\u2190 A.heap size + 1 2. A[heap size \u2212 1]\u2190 k. j\u2190 heap size \u2212 1 j\u2190 Parent(j) 3. 4. while (j (cid:54)= 0 and A[j] > A[Parent(j)]) do 5. 6. exchange A[j] and A[Parent(j)] \u201cBubble\u201d the item up the tree. Basically swap k with A[Parent(j)] if k is bigger. Why is this correct?? Takes \u0398(1) for adding new last node (initially), and \u0398(1) for every swap. Hence \u0398(lg n) worst-case in total.",
    "13": "Max-Heap-Insert Max-Heap-Insert(48), first add at \u201clast node\u201d. Need to swap 48 with parent 30, because 48 > 30.",
    "14": "Max-Heap-Insert 48 has now moved-up Now need to swap 48 with parent 45, because 48 > 45.",
    "15": "Max-Heap-Insert Done. 48 is less than root 88, no swap needed.",
    "16": "Priority Queues A Priority queue is a Data Structure for storing collections of elements. They di\ufb00er in their access policy compared to Lists, Stacks and Queues: (cid:73) Every element is associated with a key, which is taken from some linearly ordered set, such as the integers. (cid:73) Keys represent priorities: A larger key means a higher priority. Classic application is for access to resources like printers, when di\ufb00erent users may have varying priority levels.",
    "17": "Priority Queue operations Methods of PriorityQueue: (cid:73) insertItem(k, e): Insert element e with key k. (cid:73) maxElement(): Return an element with maximum key; an error occurs if the priority queue is empty. (cid:73) removeMax(): Return and remove an element with maximum key; an error occurs if the priority queue is empty. (cid:73) isEmpty(): Return true if the priority queue is empty and false otherwise. No findElement(k) or removeItem(k) methods.",
    "18": "Implementations of Priority Queues Observation: The maximum key in a binary search tree (like a Red-Black tree) is always stored in the rightmost leaf. Therefore, all Priority Queue methods can be implemented on an Red-Black tree with running time \u0398(lg(n)) (except isEmpty which is \u0398(1)). However, using a Max Heap we can implement maxElement with Heap-Maximum in \u0398(1) time, while still having insertItem (via Max-Heap-Insert) and removeMax (via Heap-Extract-Max) in \u0398(lg(n)) time. Note Balanced Search trees can be \u201ctweaked\u201d to maintain a direct pointer to the rightmost leaf, to give \u0398(1) for maxElement.",
    "19": "Reading Material This lecture used content from sections 6.1, 6.2 and 6.3 of [CLRS]: (cid:73) I did Max-Heap-Insert more directly than the book. (cid:73) I didn\u2019t write the details of Parent, Left, Right on slides (tutorial qn). In lecture 12, I will cover: (cid:73) The method Build-Heap (cid:73) The asymptotic analysis of the running-time of the Heap algorithms (6.1-6.3 of [CLRS]) (cid:73) Heapsort and its running time (6.4 of [CLRS])"
}